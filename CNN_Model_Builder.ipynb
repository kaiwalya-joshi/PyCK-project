{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vS7lg4uMVJp"
   },
   "source": [
    "# Importing and Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sXN0Lb7Gypb5",
    "outputId": "7ad9c758-aafc-4269-f417-7279ded1db8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emnist\n",
      "  Downloading emnist-0.0-py3-none-any.whl (7.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\shri\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from emnist) (1.21.0)\n",
      "Collecting requests\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.61.2-py2.py3-none-any.whl (76 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\shri\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm->emnist) (0.4.4)\n",
      "Installing collected packages: urllib3, idna, chardet, certifi, tqdm, requests, emnist\n",
      "Successfully installed certifi-2021.5.30 chardet-4.0.0 emnist-0.0 idna-2.10 requests-2.25.1 tqdm-4.61.2 urllib3-1.26.6\n"
     ]
    }
   ],
   "source": [
    "!pip install emnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4GO7Sbb4u_Ne",
    "outputId": "80cfc0b7-cfc6-49e3-ef5b-272f8028e274"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15436/3940603590.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0memnist\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mextract_training_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_test_samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#extracting data from emnist dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_training_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'letters'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from emnist import extract_training_samples, extract_test_samples\n",
    "#extracting data from emnist dataset\n",
    "x_train, y_train = extract_training_samples('letters')\n",
    "x_test, y_test = extract_test_samples('letters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VX-P3v2Cu_Nh",
    "outputId": "acfce265-ed86-4add-d0d8-9b4be1ea6455"
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)# Since we are using emnist dataset no need to make the image dimensions uniform \n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train.dtype) # y_test will also have the same datatype\n",
    "img_rows = img_cols = 28\n",
    "input_shape = (img_rows,img_cols,1)\n",
    "x_train , x_test= x_train.reshape(x_train.shape[0], img_rows, img_cols,1),x_test.reshape(x_test.shape[0], img_rows, img_cols,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "_2eAH4Bju_Ni",
    "outputId": "703a939b-8690-4d6a-b6fc-f63f932fadd7"
   },
   "outputs": [],
   "source": [
    "#displaying random image \n",
    "import matplotlib.pyplot as plt\n",
    "sample_img=x_train[27]\n",
    "plt.imshow(sample_img.reshape(28,28),cmap='gray')\n",
    "plt.show()\n",
    "print(y_train[27])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "7DeXyAgdu_Ni",
    "outputId": "194bfc34-53f1-4b22-c9f6-0bd0771304ae"
   },
   "outputs": [],
   "source": [
    "#Normalizing dataset \n",
    "x_train=tf.keras.utils.normalize(x_train,axis=1) \n",
    "x_test=tf.keras.utils.normalize(x_test,axis=1)\n",
    "sample_img=x_train[27]\n",
    "plt.imshow(sample_img.reshape(28,28),cmap='gray')\n",
    "plt.show() # after normalizing the intensity of the image decreases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqyHE_OZu_Nj"
   },
   "source": [
    "# One HOT encoding the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jQpvVp9su_Nj",
    "outputId": "e354ca88-b806-49b9-968d-a0390c2bd316"
   },
   "outputs": [],
   "source": [
    "#checking the no. of distinct elements in the labels \n",
    "depth_train = np.unique(y_train).size\n",
    "depth_test = np.unique(y_test).size\n",
    "\n",
    "print(type(depth_train))\n",
    "print(type(depth_test))\n",
    "\n",
    "#making the indices begin from 0\n",
    "y_train = y_train - 1\n",
    "y_test = y_test - 1\n",
    "\n",
    "#printing the labels\n",
    "print(depth_train)\n",
    "print(np.unique(y_train))\n",
    "print(depth_test)\n",
    "print(np.unique(y_test))\n",
    "num_classes=depth_train= depth_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SUSGpL9Eu_Nk",
    "outputId": "618ddc44-b663-4d5f-dea1-dd04cff0b9a3"
   },
   "outputs": [],
   "source": [
    "#converting class vectors to binary class vectors\n",
    "y_train= tf.one_hot(y_train,depth_train,on_value=1.0, off_value=0.0,axis=-1)\n",
    "y_test= tf.one_hot(y_test,depth_test,on_value=1.0, off_value=0.0,axis=-1)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQRDbesXu_Nl"
   },
   "source": [
    "# Creating the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tkjAozjru_Nm",
    "outputId": "bb14148d-470b-46c7-9930-a56db26985cb"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "#Testing various CNN architectures \n",
    "conv_layers=[3]\n",
    "conv_layer_sizes=[64]\n",
    "dense_layer_sizes=[128]\n",
    "dense_layers=[3]\n",
    "\n",
    "for conv_layer in conv_layers:\n",
    "    for conv_layer_size in conv_layer_sizes:\n",
    "        for dense_layer in dense_layers:\n",
    "            for dense_layer_size in dense_layer_sizes:\n",
    "                NAME=f\"{conv_layer}-clayers-{conv_layer_size}-csize-{dense_layer}-dlayers-{dense_layer_size}-dsize-{int(time.time())}\"\n",
    "                tensorboard=TensorBoard(log_dir=f\"logs/{NAME}\")\n",
    "                model = Sequential()\n",
    "                model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))#input layer\n",
    "                for i in range(conv_layer-1):\n",
    "                \n",
    "                    model.add(Conv2D(conv_layer_size, (3, 3), activation='relu'))\n",
    "                    model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "                    model.add(Dropout(0.5))            \n",
    "                \n",
    "                model.add(Flatten())                \n",
    "                model.add(Dense( dense_layer_size, activation='relu'))\n",
    "                model.add(Dropout(0.25)) #prevent overfitting\n",
    "                for i in range(dense_layer-1):\n",
    "\n",
    "                    model.add(Dense( dense_layer_size, activation='relu'))\n",
    "                    model.add(Dropout(0.25))\n",
    "                    \n",
    "                model.add(Dense(num_classes, activation='softmax'))#final output layer\n",
    "                # Compile the model\n",
    "                model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "                history=model.fit(x_train,y_train,batch_size=128,epochs =10,validation_split=0.25,callbacks =[tensorboard],shuffle=True)\n",
    "                model.save(f\"emnist_cnn_model_{NAME}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the graphs of accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "iG8P084ku_Nm",
    "outputId": "b9e75f0e-e2b1-40d2-9036-bafe03538f74"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f15a66eaa487>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# summarize history for accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
