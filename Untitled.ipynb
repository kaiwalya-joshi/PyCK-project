{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from emnist import extract_training_samples, extract_test_samples\n",
    "x_train, y_train = extract_training_samples('letters')\n",
    "x_test, y_test = extract_test_samples('letters')\n",
    "x_train\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124800, 28, 28)\n",
      "(124800,)\n",
      "(20800, 28, 28)\n",
      "(20800,)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)# Since we are using emnist dataset no need to make the image dimensions uniform \n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train.dtype)# y_test will also have the same datatype\n",
    "img_rows = img_cols = 28\n",
    "input_shape = (img_rows,img_cols,1)\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sample_img=x_train[27]\n",
    "plt.imshow(sample_img,cmap='gray')\n",
    "print(y_train[27])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x214641df8b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAP+klEQVR4nO3dW2xd9ZXH8d/K/cItF2KCY0gHIhFAmjCKwiCiEaNCFSIk0hdUHkaMBiZ9KFIr9WEQ81Ck0UhoNG3FU6VUoKajDlUlbnlAUCaqAghB4kRuEsyES0hwnGBzDbmBibPmwTsdAz7rb84+++xj/78fybJ91tnnrBz8Y+9z/vu//+buAjD9zai7AQDtQdiBTBB2IBOEHcgEYQcyMaudT2ZmfPQPVMzdbaLbS+3ZzWyDmR0ws7fN7IEyjwWgWtbsOLuZzZT0pqTbJB2RtEvS3e7eH2zDnh2oWBV79nWS3nb3g+4+Iun3ku4s8XgAKlQm7N2SBsb9fqS47SvMbLOZ9ZpZb4nnAlBS5R/QufsWSVskDuOBOpXZsw9K6hn3+4riNgAdqEzYd0laZWbfMbM5kn4gaVtr2gLQak0fxrv7WTO7X9LzkmZKeszdX29ZZwBaqumht6aejPfsQOUqOakGwNRB2IFMEHYgE4QdyARhBzJB2IFMtHU+e5XmzJkT1mfNiv+pZ86cCetchRdTHXt2IBOEHcgEYQcyQdiBTBB2IBOEHcjElBp6W7p0acPazTffHG7b1dUV1nfu3BnW+/sbXkdTIyMj4bZAJ2DPDmSCsAOZIOxAJgg7kAnCDmSCsAOZIOxAJqbU1WUfeeSRhrWenp6GNUk6depUWB8YGAjru3btalh7+eWXw20/+OCDsI7mzJw5M6x3d39jNbJJGxyM1zsZHR1t+rGrxtVlgcwRdiAThB3IBGEHMkHYgUwQdiAThB3IxJQaZ496PXjwYLhtar76yZMnw7rZhEOXkqTe3t5w22effTasf/rpp2E91du5c+fC+lSVGkdfvHhxWF+/fn3D2owZ8X7upZdeCuvDw8NhvU6NxtlLXbzCzA5JOiFpVNJZd19b5vEAVKcVV6r5e3f/sAWPA6BCvGcHMlE27C7pj2a228w2T3QHM9tsZr1mFr+xBVCpsofx69190MyWSXrBzP7X3V8cfwd33yJpi1T+AzoAzSu1Z3f3weL7sKSnJK1rRVMAWq/psJvZQjO78PzPkr4naX+rGgPQWmUO47skPVWMP8+S9N/u/lxLumogGkv/7LPPwm3Lnk8QLQm9bl18QLNy5cqwPjQ0FNZTY7579+5tWJvK17RfsmRJWL/66qvDejQOnxpnv/HGG8P6a6+9FtY7cRy+6bC7+0FJf93CXgBUiKE3IBOEHcgEYQcyQdiBTBB2IBNTaorrmjVrGtauv/76cNu1a+MJeQsWLAjr8+bNa1iLpr9K6amaKR9+GM8z2rFjR1O1yTx2lVLDX6khzVWrVoX1+fPnN6yl/ptdcMEFYf3AgQNh/bnn4lHos2fPhvUyuJQ0kDnCDmSCsAOZIOxAJgg7kAnCDmSCsAOZaMUFJ9umr6+vYS017vnee++F9dtvvz2sX3755Q1rqTHblNR4c1dXV1i/4447mn7u7du3h/XU1OEyl7GOxsGl9DLcqbHwMssqp86NiM676FTs2YFMEHYgE4QdyARhBzJB2IFMEHYgE4QdyMSUGmePpMZ7P/7447Cemtd9ySWXNKwtXLgw3LZq0WWuU5dbPnz4cFhPnb+QWk46ul7ChRdeGG6bWpJ57ty5Yf306dNhPZL6e/r888+bfuy6sGcHMkHYgUwQdiAThB3IBGEHMkHYgUwQdiAT02acfenSpWH91ltvDeupcfinn366Ye22224Lt03NR09Jza2O5sNfc8014bap8eJFixaF9XfeeSesR2Pd69evD7dNjbN/+eWXYb2M1PkD+/fvD+tVXhe+Wck9u5k9ZmbDZrZ/3G2LzewFM3ur+B7/RQCo3WQO438jacPXbntA0nZ3XyVpe/E7gA6WDLu7vyjp68e4d0raWvy8VdKm1rYFoNWafc/e5e7Hip/fl9TwTamZbZa0ucnnAdAipT+gc3ePFmx09y2StkjlF3YE0Lxmh96GzGy5JBXfh1vXEoAqNBv2bZLuKX6+R9IzrWkHQFWSh/Fm9rikWyQtNbMjkn4m6WFJfzCzeyUdlnRXlU1OxkcffRTWU+PBJ06cCOuvvvpqw9rQ0FC47XXXXRfWly1bFtZXr14d1qPrp6euaT979uywfsUVV4T17u7usB6dI7BixYpw29Sc8jLj7KnHPnr0aFhP/b11omTY3f3uBqXvtrgXABXidFkgE4QdyARhBzJB2IFMEHYgExZd6rflT1bjGXRlL/d86tSphrXU8NasWfGgR2rp4htuuCGsb9q0qWHt4osvDrft7+8P68ePHw/rqem30b8tNYV1ZGQkrJ85cyasR8tNf/LJJ+G2O3bsCOvDw517Hpm7T/gHyZ4dyARhBzJB2IFMEHYgE4QdyARhBzJB2IFMTJtLSadE4+Rlpc5VSE3FTNVfeeWVsB5d9vimm24Ktx0dHQ3r7TwP4+tS5y+kRL0PDg6G26YuLT4VsWcHMkHYgUwQdiAThB3IBGEHMkHYgUwQdiAT2YyzT2Wpcfg9e/Y0rL355pvhtldeeWVYT82lT83V71QXXXRRWE/NtU+Nw0/JJZsBTA+EHcgEYQcyQdiBTBB2IBOEHcgEYQcyMTUHSfEV0bzt1FLUqaWJr7322rBe9nr8VYrmw/f09ITbLl++PKzv27cvrPf19YX1Osbhk3t2M3vMzIbNbP+42x4ys0Ez6yu+NlbbJoCyJnMY/xtJGya4/Zfuvqb4era1bQFotWTY3f1FSdPvGj1AZsp8QHe/me0tDvMXNbqTmW02s14z6y3xXABKajbsv5J0laQ1ko5J+nmjO7r7Fndf6+5rm3wuAC3QVNjdfcjdR939nKRfS1rX2rYAtFpTYTez8eMS35e0v9F9AXSG5Di7mT0u6RZJS83siKSfSbrFzNZIckmHJP2wuhZRRura66l523PmzGllO9/KuXPnwnqZa9rPmBHv55YtWxbWN26MR5svvfTSsB6tBXD8+PFw22Ylw+7ud09w86MV9AKgQpwuC2SCsAOZIOxAJgg7kAnCDmSCKa7TXOpSz93d3WF97ty5rWznK1LLaPf394f1mTNnhvVoWDH1uqSGLFevXh3WV6xYEdajYcXnn38+3LZZ7NmBTBB2IBOEHcgEYQcyQdiBTBB2IBOEHcgE4+zT3GWXXRbWV65cGdZTU0FTommohw4dCrfdsWNHWE/1tmbNmoa1q666Ktw2JTXGv2HDRNdo/X/33Xdfw1rZ17zh41byqAA6DmEHMkHYgUwQdiAThB3IBGEHMkHYgUwwzj4NRHOvU5dEXrBgQVgvu7RwNG97aGgo3DY13z1lYGCgYS11/sGSJUvCeuoy1qnLYNeBPTuQCcIOZIKwA5kg7EAmCDuQCcIOZIKwA5lgnH0aiMbZU9cvnzdvXlg/efJkUz2dF42VHzhwINy27Bj/u+++2/RjnzlzJqyPjIyE9SeffDKsp+byVyG5ZzezHjP7k5n1m9nrZvbj4vbFZvaCmb1VfF9UfbsAmjWZw/izkn7q7tdK+ltJPzKzayU9IGm7u6+StL34HUCHSobd3Y+5+57i5xOS3pDULelOSVuLu22VtKmiHgG0wLd6z25mKyXdIOk1SV3ufqwovS+pq8E2myVtLtEjgBaY9KfxZnaBpCck/cTdPxtf87FZARPODHD3Le6+1t3XluoUQCmTCruZzdZY0H/n7uc/Zhwys+VFfbmk4WpaBNAKycN4GxvXeVTSG+7+i3GlbZLukfRw8f2ZSjpEKamlh6s2OjrasPbFF1/U9tyHDx8Ot01Nv00t+Xz69OmwHvVWlcm8Z79Z0j9I2mdmfcVtD2os5H8ws3slHZZ0VyUdAmiJZNjd/WVJjXYP321tOwCqwumyQCYIO5AJwg5kgrADmSDsQCaY4opSUuPFR48ebVhLTSOtUupS0HX2VhX27EAmCDuQCcIOZIKwA5kg7EAmCDuQCcIOZIJx9mkuNV6cWlo4NR49ODgY1nfu3NmwlprzjdZizw5kgrADmSDsQCYIO5AJwg5kgrADmSDsQCYYZ58GorHy3bt3h9umriu/cOHCsD4wMBDWjx8/HtbRPuzZgUwQdiAThB3IBGEHMkHYgUwQdiAThB3IhKXmK5tZj6TfSuqS5JK2uPsjZvaQpH+W9EFx1wfd/dnEY8VPhrabP39+WJ89e3ZYT62xXvUa7Pgmd5/w5InJnFRzVtJP3X2PmV0oabeZvVDUfunu/9mqJgFUZzLrsx+TdKz4+YSZvSGpu+rGALTWt3rPbmYrJd0g6bXipvvNbK+ZPWZmixpss9nMes2st1yrAMpIvmf/yx3NLpC0Q9K/u/uTZtYl6UONvY//N0nL3f2fEo/Be/YOw3v26afRe/ZJ7dnNbLakJyT9zt2fLB5wyN1H3f2cpF9LWteqZgG0XjLsNjYt6lFJb7j7L8bdvnzc3b4vaX/r2wPQKpMZelsv6SVJ+ySdn0v5oKS7Ja3R2GH8IUk/LD7Mix6Lw3igYo0O4yf9nr0VCDtQvVLv2QFMfYQdyARhBzJB2IFMEHYgE4QdyARhBzJB2IFMEHYgE4QdyARhBzJB2IFMEHYgE4QdyES7l2z+UNLhcb8vLW7rRJ3aW6f2JdFbs1rZ25WNCm2dz/6NJzfrdfe1tTUQ6NTeOrUvid6a1a7eOIwHMkHYgUzUHfYtNT9/pFN769S+JHprVlt6q/U9O4D2qXvPDqBNCDuQiVrCbmYbzOyAmb1tZg/U0UMjZnbIzPaZWV/d69MVa+gNm9n+cbctNrMXzOyt4vuEa+zV1NtDZjZYvHZ9Zraxpt56zOxPZtZvZq+b2Y+L22t97YK+2vK6tf09u5nNlPSmpNskHZG0S9Ld7t7f1kYaMLNDkta6e+0nYJjZ30k6Kem37n59cdt/SPrY3R8u/ke5yN3/pUN6e0jSybqX8S5WK1o+fplxSZsk/aNqfO2Cvu5SG163Ovbs6yS97e4H3X1E0u8l3VlDHx3P3V+U9PHXbr5T0tbi560a+2Npuwa9dQR3P+bue4qfT0g6v8x4ra9d0Fdb1BH2bkkD434/os5a790l/dHMdpvZ5rqbmUDXuGW23pfUVWczE0gu491OX1tmvGNeu2aWPy+LD+i+ab27/42k2yX9qDhc7Ug+9h6sk8ZOfyXpKo2tAXhM0s/rbKZYZvwJST9x98/G1+p87Sboqy2vWx1hH5TUM+73FcVtHcHdB4vvw5KeUuctRT10fgXd4vtwzf38RSct4z3RMuPqgNeuzuXP6wj7LkmrzOw7ZjZH0g8kbauhj28ws4XFBycys4WSvqfOW4p6m6R7ip/vkfRMjb18Racs491omXHV/NrVvvy5u7f9S9JGjX0i/46kf62jhwZ9/ZWkPxdfr9fdm6THNXZY96XGPtu4V9ISSdslvSXpfyQt7qDe/ktjS3vv1ViwltfU23qNHaLvldRXfG2s+7UL+mrL68bpskAm+IAOyARhBzJB2IFMEHYgE4QdyARhBzJB2IFM/B9uiz3NYluMlAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Normalizing dataset \n",
    "x_train=tf.keras.utils.normalize(x_train,axis=1) \n",
    "x_test=tf.keras.utils.normalize(x_test,axis=1)\n",
    "sample_img=x_train[27]\n",
    "plt.imshow(sample_img,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One HOT encoding the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int32'>\n",
      "<class 'numpy.int32'>\n",
      "26\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26]\n",
      "26\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26]\n"
     ]
    }
   ],
   "source": [
    "from numpy import argmax\n",
    "depth_train = np.unique(y_train).size\n",
    "depth_test = np.unique(y_test).size\n",
    "depth_train= np.int32(depth_train)\n",
    "depth_test= np.int32(depth_test)\n",
    "print(type(depth_train))\n",
    "print(type(depth_test))\n",
    "print(depth_train)\n",
    "print(np.unique(y_train))\n",
    "print(depth_test)\n",
    "print(np.unique(y_test))\n",
    "\n",
    "num_classes=depth_train= depth_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], shape=(124800, 26), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#converting class vectors to binary class vectors\n",
    "y_train= tf.one_hot(y_train,depth_train,on_value=1.0, off_value=0.0,axis=-1)\n",
    "y_test= tf.one_hot(y_test,depth_test,on_value=1.0, off_value=0.0,axis=-1)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "780/780 [==============================] - 116s 147ms/step - loss: 3.1322 - accuracy: 0.0410 - val_loss: 3.1241 - val_accuracy: 0.0546\n",
      "Epoch 2/10\n",
      "780/780 [==============================] - 118s 152ms/step - loss: 3.1217 - accuracy: 0.0532 - val_loss: 3.1120 - val_accuracy: 0.0831\n",
      "Epoch 3/10\n",
      "780/780 [==============================] - 122s 157ms/step - loss: 3.1099 - accuracy: 0.0698 - val_loss: 3.0975 - val_accuracy: 0.1169\n",
      "Epoch 4/10\n",
      "780/780 [==============================] - 122s 157ms/step - loss: 3.0945 - accuracy: 0.0875 - val_loss: 3.0788 - val_accuracy: 0.1607\n",
      "Epoch 5/10\n",
      "780/780 [==============================] - 122s 157ms/step - loss: 3.0749 - accuracy: 0.1058 - val_loss: 3.0540 - val_accuracy: 0.2080\n",
      "Epoch 6/10\n",
      "780/780 [==============================] - 124s 159ms/step - loss: 3.0494 - accuracy: 0.1233 - val_loss: 3.0214 - val_accuracy: 0.2508\n",
      "Epoch 7/10\n",
      "780/780 [==============================] - 130s 166ms/step - loss: 3.0151 - accuracy: 0.1427 - val_loss: 2.9786 - val_accuracy: 0.2862\n",
      "Epoch 8/10\n",
      "780/780 [==============================] - 126s 162ms/step - loss: 2.9719 - accuracy: 0.1616 - val_loss: 2.9234 - val_accuracy: 0.3137\n",
      "Epoch 9/10\n",
      "780/780 [==============================] - 116s 148ms/step - loss: 2.9203 - accuracy: 0.1787 - val_loss: 2.8545 - val_accuracy: 0.3357\n",
      "Epoch 10/10\n",
      "780/780 [==============================] - 115s 147ms/step - loss: 2.8531 - accuracy: 0.1988 - val_loss: 2.7701 - val_accuracy: 0.3570\n",
      "Epoch 1/10\n",
      "780/780 [==============================] - 136s 173ms/step - loss: 3.1310 - accuracy: 0.0432 - val_loss: 3.1219 - val_accuracy: 0.0583\n",
      "Epoch 2/10\n",
      "780/780 [==============================] - 127s 163ms/step - loss: 3.1184 - accuracy: 0.0585 - val_loss: 3.1077 - val_accuracy: 0.0851\n",
      "Epoch 3/10\n",
      "780/780 [==============================] - 129s 166ms/step - loss: 3.1038 - accuracy: 0.0728 - val_loss: 3.0900 - val_accuracy: 0.1172\n",
      "Epoch 4/10\n",
      "780/780 [==============================] - 129s 165ms/step - loss: 3.0852 - accuracy: 0.0920 - val_loss: 3.0665 - val_accuracy: 0.1548\n",
      "Epoch 5/10\n",
      "780/780 [==============================] - 132s 169ms/step - loss: 3.0595 - accuracy: 0.1127 - val_loss: 3.0338 - val_accuracy: 0.2034\n",
      "Epoch 6/10\n",
      "780/780 [==============================] - 133s 171ms/step - loss: 3.0237 - accuracy: 0.1322 - val_loss: 2.9880 - val_accuracy: 0.2617\n",
      "Epoch 7/10\n",
      "780/780 [==============================] - 135s 173ms/step - loss: 2.9748 - accuracy: 0.1594 - val_loss: 2.9238 - val_accuracy: 0.3190\n",
      "Epoch 8/10\n",
      "780/780 [==============================] - 129s 165ms/step - loss: 2.9069 - accuracy: 0.1895 - val_loss: 2.8351 - val_accuracy: 0.3686\n",
      "Epoch 9/10\n",
      "780/780 [==============================] - 129s 165ms/step - loss: 2.8159 - accuracy: 0.2212 - val_loss: 2.7169 - val_accuracy: 0.4014\n",
      "Epoch 10/10\n",
      "780/780 [==============================] - 125s 161ms/step - loss: 2.7035 - accuracy: 0.2487 - val_loss: 2.5707 - val_accuracy: 0.4229\n",
      "Epoch 1/10\n",
      "780/780 [==============================] - 144s 183ms/step - loss: 3.1270 - accuracy: 0.0466 - val_loss: 3.1137 - val_accuracy: 0.0545\n",
      "Epoch 2/10\n",
      "780/780 [==============================] - 149s 191ms/step - loss: 3.1082 - accuracy: 0.0653 - val_loss: 3.0919 - val_accuracy: 0.0909\n",
      "Epoch 3/10\n",
      "780/780 [==============================] - 140s 180ms/step - loss: 3.0852 - accuracy: 0.0882 - val_loss: 3.0634 - val_accuracy: 0.1596\n",
      "Epoch 4/10\n",
      "780/780 [==============================] - 140s 180ms/step - loss: 3.0538 - accuracy: 0.1157 - val_loss: 3.0232 - val_accuracy: 0.2272\n",
      "Epoch 5/10\n",
      "780/780 [==============================] - 147s 188ms/step - loss: 3.0095 - accuracy: 0.1471 - val_loss: 2.9649 - val_accuracy: 0.2857\n",
      "Epoch 6/10\n",
      "780/780 [==============================] - 146s 188ms/step - loss: 2.9456 - accuracy: 0.1778 - val_loss: 2.8795 - val_accuracy: 0.3438\n",
      "Epoch 7/10\n",
      "780/780 [==============================] - 145s 186ms/step - loss: 2.8528 - accuracy: 0.2173 - val_loss: 2.7563 - val_accuracy: 0.3953\n",
      "Epoch 8/10\n",
      "780/780 [==============================] - 141s 181ms/step - loss: 2.7235 - accuracy: 0.2584 - val_loss: 2.5885 - val_accuracy: 0.4331\n",
      "Epoch 9/10\n",
      "780/780 [==============================] - 142s 182ms/step - loss: 2.5650 - accuracy: 0.2943 - val_loss: 2.3845 - val_accuracy: 0.4582\n",
      "Epoch 10/10\n",
      "780/780 [==============================] - 143s 184ms/step - loss: 2.3908 - accuracy: 0.3239 - val_loss: 2.1726 - val_accuracy: 0.4763\n",
      "Epoch 1/10\n",
      "780/780 [==============================] - 129s 163ms/step - loss: 3.1341 - accuracy: 0.0409 - val_loss: 3.1311 - val_accuracy: 0.0595\n",
      "Epoch 2/10\n",
      "780/780 [==============================] - 125s 160ms/step - loss: 3.1314 - accuracy: 0.0432 - val_loss: 3.1281 - val_accuracy: 0.0781\n",
      "Epoch 3/10\n",
      "780/780 [==============================] - 122s 156ms/step - loss: 3.1287 - accuracy: 0.0487 - val_loss: 3.1250 - val_accuracy: 0.0963\n",
      "Epoch 4/10\n",
      "780/780 [==============================] - 120s 153ms/step - loss: 3.1262 - accuracy: 0.0528 - val_loss: 3.1217 - val_accuracy: 0.1107\n",
      "Epoch 5/10\n",
      "780/780 [==============================] - 118s 152ms/step - loss: 3.1232 - accuracy: 0.0566 - val_loss: 3.1178 - val_accuracy: 0.1156\n",
      "Epoch 6/10\n",
      "780/780 [==============================] - 116s 149ms/step - loss: 3.1202 - accuracy: 0.0610 - val_loss: 3.1133 - val_accuracy: 0.1202\n",
      "Epoch 7/10\n",
      "780/780 [==============================] - 120s 154ms/step - loss: 3.1158 - accuracy: 0.0653 - val_loss: 3.1080 - val_accuracy: 0.1193\n",
      "Epoch 8/10\n",
      "780/780 [==============================] - 118s 151ms/step - loss: 3.1116 - accuracy: 0.0683 - val_loss: 3.1016 - val_accuracy: 0.1222\n",
      "Epoch 9/10\n",
      "780/780 [==============================] - 117s 150ms/step - loss: 3.1057 - accuracy: 0.0711 - val_loss: 3.0939 - val_accuracy: 0.1254\n",
      "Epoch 10/10\n",
      "780/780 [==============================] - 114s 146ms/step - loss: 3.0995 - accuracy: 0.0741 - val_loss: 3.0847 - val_accuracy: 0.1298\n",
      "Epoch 1/10\n",
      "780/780 [==============================] - 125s 159ms/step - loss: 3.1346 - accuracy: 0.0386 - val_loss: 3.1308 - val_accuracy: 0.0389\n",
      "Epoch 2/10\n",
      "780/780 [==============================] - 126s 162ms/step - loss: 3.1321 - accuracy: 0.0405 - val_loss: 3.1276 - val_accuracy: 0.0449\n",
      "Epoch 3/10\n",
      "780/780 [==============================] - 128s 164ms/step - loss: 3.1293 - accuracy: 0.0456 - val_loss: 3.1245 - val_accuracy: 0.0539\n",
      "Epoch 4/10\n",
      "780/780 [==============================] - 129s 166ms/step - loss: 3.1263 - accuracy: 0.0487 - val_loss: 3.1210 - val_accuracy: 0.0655\n",
      "Epoch 5/10\n",
      "780/780 [==============================] - 129s 166ms/step - loss: 3.1234 - accuracy: 0.0524 - val_loss: 3.1170 - val_accuracy: 0.0799\n",
      "Epoch 6/10\n",
      "780/780 [==============================] - 129s 166ms/step - loss: 3.1199 - accuracy: 0.0563 - val_loss: 3.1123 - val_accuracy: 0.0970\n",
      "Epoch 7/10\n",
      "780/780 [==============================] - 127s 162ms/step - loss: 3.1154 - accuracy: 0.0608 - val_loss: 3.1064 - val_accuracy: 0.1156\n",
      "Epoch 8/10\n",
      "780/780 [==============================] - 129s 165ms/step - loss: 3.1103 - accuracy: 0.0634 - val_loss: 3.0993 - val_accuracy: 0.1348\n",
      "Epoch 9/10\n",
      "780/780 [==============================] - 128s 163ms/step - loss: 3.1041 - accuracy: 0.0689 - val_loss: 3.0903 - val_accuracy: 0.1520\n",
      "Epoch 10/10\n",
      "780/780 [==============================] - 129s 165ms/step - loss: 3.0955 - accuracy: 0.0741 - val_loss: 3.0789 - val_accuracy: 0.1682\n",
      "Epoch 1/10\n",
      "780/780 [==============================] - 149s 190ms/step - loss: 3.1322 - accuracy: 0.0404 - val_loss: 3.1259 - val_accuracy: 0.0662\n",
      "Epoch 2/10\n",
      "780/780 [==============================] - 147s 189ms/step - loss: 3.1262 - accuracy: 0.0474 - val_loss: 3.1187 - val_accuracy: 0.0841\n",
      "Epoch 3/10\n",
      "780/780 [==============================] - 135s 174ms/step - loss: 3.1199 - accuracy: 0.0528 - val_loss: 3.1107 - val_accuracy: 0.1073\n",
      "Epoch 4/10\n",
      "780/780 [==============================] - 143s 183ms/step - loss: 3.1128 - accuracy: 0.0583 - val_loss: 3.1014 - val_accuracy: 0.1373\n",
      "Epoch 5/10\n",
      "780/780 [==============================] - 156s 200ms/step - loss: 3.1041 - accuracy: 0.0672 - val_loss: 3.0898 - val_accuracy: 0.1704\n",
      "Epoch 6/10\n",
      "780/780 [==============================] - 140s 179ms/step - loss: 3.0931 - accuracy: 0.0754 - val_loss: 3.0751 - val_accuracy: 0.1950\n",
      "Epoch 7/10\n",
      "780/780 [==============================] - 136s 175ms/step - loss: 3.0801 - accuracy: 0.0811 - val_loss: 3.0564 - val_accuracy: 0.2164\n",
      "Epoch 8/10\n",
      "780/780 [==============================] - 136s 174ms/step - loss: 3.0630 - accuracy: 0.0895 - val_loss: 3.0322 - val_accuracy: 0.2371\n",
      "Epoch 9/10\n",
      "780/780 [==============================] - 139s 178ms/step - loss: 3.0417 - accuracy: 0.0985 - val_loss: 3.0010 - val_accuracy: 0.2551\n",
      "Epoch 10/10\n",
      "780/780 [==============================] - 317s 406ms/step - loss: 3.0135 - accuracy: 0.1091 - val_loss: 2.9608 - val_accuracy: 0.2778\n",
      "Epoch 1/10\n",
      " 22/780 [..............................] - ETA: 3:08 - loss: 3.1534 - accuracy: 0.0380"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "#Testing various CNN architectures \n",
    "conv_layers=[2,3]\n",
    "conv_layer_sizes=[64]\n",
    "dense_layer_sizes=[256,512]\n",
    "dense_layers=[1]\n",
    "\n",
    "for conv_layer in conv_layers:\n",
    "    for conv_layer_size in c2onv_layer_sizes:\n",
    "        for dense_layer in dense_layers:\n",
    "            for dense_layer_size in dense_layer_sizes:\n",
    "                NAME=f\"{conv_layer}-clayers-{conv_layer_size}-csize-{dense_layer}-dlayers-{dense_layer_size}-dsize-{int(time.time())}\"\n",
    "                tensorboard=TensorBoard(log_dir=f\"logs/{NAME}\")\n",
    "                model = Sequential()\n",
    "                model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))#input layer\n",
    "                for i in range(conv_layer-1):\n",
    "                \n",
    "                    model.add(Conv2D(conv_layer_size, (3, 3), activation='relu'))\n",
    "                    model.add(MaxPooling2D(pool_size=(2, 2)))             \n",
    "                    model.add(Dropout(0.25)) #prevent overfitting\n",
    "                model.add(Flatten())\n",
    "                for i in range(dense_layer):\n",
    "\n",
    "                    model.add(Dense( dense_layer_size, activation='relu'))\n",
    "                    model.add(Dropout(0.5))\n",
    "                model.add(Dense(num_classes, activation='softmax'))#final output layer\n",
    "                              # Compile the model\n",
    "                model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adadelta(),\n",
    "                              metrics=['accuracy'])\n",
    "                model.fit(x_train,y_train,batch_size=128,epochs =10,validation_split=0.25,callbacks =[tensorboard])\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
